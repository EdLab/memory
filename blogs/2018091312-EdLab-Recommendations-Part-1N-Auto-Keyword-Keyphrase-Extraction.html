<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="" />
    <meta name="author" content="" />

    <title>EdLab Recommendations Part 1/N: Auto Keyword / Keyphrase Extraction | EdLab Blog</title>

    <!-- Bootstrap core CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
      integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh"
      crossorigin="anonymous"
    />
    <!-- Custom styles for this template -->
    <link href="../css/styles.css" rel="stylesheet" />
  </head>

  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
      <div class="container">
        <a class="navbar-brand" href="/">EdLab Archive</a>
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarResponsive"
          aria-controls="navbarResponsive"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
              <a class="nav-link" href="../blogs">Blogs</a>
            </li>
            <li class="nav-item">
              <a class="nav-link " href="../profiles">Profiles</a>
            </li>
            <li class="nav-item ">
              <a class="nav-link" href="../events">Events</a>
            </li>
            <li class="nav-item ">
              <a class="nav-link" href="../projects">Projects</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container content">
      <div class="row">
        <!-- Post Content Column -->
        <div class="col-lg-8">
          <div class="back-link">
            <a href="./"> &lt; back to list</a>
          </div>
          <!-- Title -->
          <h1 class="mt-4">EdLab Recommendations Part 1/N: Auto Keyword / Keyphrase Extraction</h1>
          <p class="lead">
            Srujan.Routhu
          </p>
          <hr />

          <!-- Date/Time -->
          <p>
            September 13, 2018
          </p>

          <hr />

          <!-- Post Content -->

          <p>
            <p>In this post, I am going to outline the first half the process I followed in the development of our new recommendation system - automatically extracting keywords and keyphrases to attach to our articles. Attaching keywords to our articles gives us a great starting point in developing a system to suggest similar articles, as it is far more efficient to compare keywords between articles than to compare the whole bodies of text.<br /></p><p><br /></p><p>This is still very much a work in progress, and I will scrap the whole thing if the results after deployment are unexpected. The post itself is a demonstration of each step of the process, and I am testing this whole model on NLT articles to see if it actually works. I am going to demo the process on <a href="https://edlab.tc.columbia.edu/people/9318-MelanieHering" target="_blank">Melanie</a>'s latest article on NLT - <a href="https://newlearningtimes.com/cms/article/5579/can-vr-rehabilitation-programs-shed-light-on" target="_blank">Can VR Rehabilitation Programs Shed Light on Learning After a Stroke?</a></p><p><br /></p><p>The first step in the process is to identify candidates for keywords and key phrases. The brute force approach is to simply consider <i>all</i> words and phrases in the text body as candidates. But we can be a bit more scientific about this, I think. There are many ways to do this, and this is where my limited artistic ability comes into use. A simple approach is to remove all the stopwords. We know 'to', 'at', 'the' and 'there' are not going to be keywords (this will unfortunately mean that one of my favorite bands &quot;The Who&quot; will never become a key phrase on our systems, but I'll have to live with this grave injustice). I think I can be a bit more artistic than just removing stopwords. I can possibly use some common Parts-of-Speech (POS) combinations and make only those phrases adhering to these patterns as candidates. One commonly used POS combination for key phrases seems to be <code>{(JJ* NN.*+ IN)? JJ* NN.*+}</code>. This matches any number of adjectives followed by at least one noun that
 may be joined by a preposition to one other adjective(s)+noun(s) 
sequence. All we need to do now in order to get out candidate phrases is to categorize each word in the article into a part of speech, and then run through them to check if they fit the pattern. Thankfully, there is a library on Python, called <a href="https://www.nltk.org/" target="_blank">NLTK </a>(Natural Language ToolKit), that helps us do this with relative ease.</p><p><br /></p><p>Following is the chunk of code I ran to extract candidate phrases from the article:</p><pre><span style="font-weight:bold;">def </span><span style="color:#990000;font-weight:bold;">extract_candidate_chunks</span>(<span style="font-style:italic;">text</span>, <span style="font-style:italic;">grammar</span><span style="font-weight:bold;">=</span><span style="color:#dd1144;background-color:#f7e7f1;">r'KT: </span><span style="color:#dd1144;background-color:#f7e7f1;"><code>{(JJ* NN.*+ IN)? JJ* NN.*+}</code>'</span>)<span style="font-weight:bold;">:<br /></span><span style="font-weight:bold;"><br /></span><span style="font-weight:bold;">    </span>punctuation <span style="font-weight:bold;">= </span><span style="color:#0086b3;">set</span>(string.punctuation)<br />    stop_words <span style="font-weight:bold;">= </span><span style="color:#0086b3;">set</span>(nltk.corpus.stopwords.words(<span style="color:#dd1144;background-color:#f7e7f1;">'english'</span>))<br /><br />    chunker <span style="font-weight:bold;">= </span>nltk.chunk.regexp.RegexpParser(<span style="font-style:italic;">grammar</span>)<br />    tagged_sents <span style="font-weight:bold;">= </span>nltk.pos_tag_sents(nltk.word_tokenize(sent) <span style="font-weight:bold;">for </span>sent <span style="font-weight:bold;">in </span>nltk.sent_tokenize(<span style="font-style:italic;">text</span>))<br />    all_chunks <span style="font-weight:bold;">= </span><span style="color:#0086b3;">list</span>(itertools.chain.from_iterable(nltk.chunk.tree2conlltags(chunker.parse(tagged_sent))<br />                                                    <span style="font-weight:bold;">for </span>tagged_sent <span style="font-weight:bold;">in </span>tagged_sents))<br /><br />    candidates <span style="font-weight:bold;">= </span>[<span style="color:#dd1144;background-color:#f7e7f1;">' '</span>.join(word <span style="font-weight:bold;">for </span>word, pos, chunk <span style="font-weight:bold;">in </span>group).lower()<br />                  <span style="font-weight:bold;">for </span>key, group <span style="font-weight:bold;">in </span>itertools.groupby(all_chunks, <span style="font-weight:bold;">lambda </span><span style="font-style:italic;">(word</span>, <span style="font-style:italic;">pos</span>, <span style="font-style:italic;">chunk</span>)<span style="font-weight:bold;">: </span>chunk <span style="font-weight:bold;">!= </span><span style="color:#dd1144;background-color:#f7e7f1;">'O'</span>) <span style="font-weight:bold;">if </span>key]<br /><br />    <span style="font-weight:bold;">return </span>[cand <span style="font-weight:bold;">for </span>cand <span style="font-weight:bold;">in </span>candidates<br />            <span style="font-weight:bold;">if </span>cand <span style="font-weight:bold;">not in </span>stop_words <span style="font-weight:bold;">and not </span><span style="color:#0086b3;">all</span>(char <span style="font-weight:bold;">in </span>punctuation <span style="font-weight:bold;">for </span>char <span style="font-weight:bold;">in </span>cand)]</pre><p><br /></p><p>And following are the bunch of keywords and key phrases that my code has identified as candidates:</p><p><br /></p><p><b>['badia', 'm. s.', 'month', 'certain motor competencies', 'initial study', 'j. f.', 'serious long-term disability', 'cognitive abilities', 'month of rehab', 'tasks prevent individuals', 'someone', 'therapy', 'cognitive improvements', 'cause of death', 'cognitive tasks', 'success', 'couras', 'other areas', 'control group', 'week', 'cognitive-motor rehabilitation in virtual reality improves motor outcomes', 'feasibility', 'j. r. o.', 'motor deficits', 'ways', 'patients', 'paper-and-pencil tasks with different levels', 'researchers in portugal', 'participants', 'method doesn \xe2\x80\x99 t deliver immediate feedback', 'seconds', 'attention', 'course many traditional rehabilitation strategies', 'improvement in motor function double', 'groups', 'cameir\xc3\xa3o', 'g. m.', 'study', 'times', 'dominant arm mobility', 'difficulty', 'vr group', 'letters', 'image', 'united states', 'stroke recovery', 'standard training', 'cognitive processes', 'addition', 'virtual reality', 's. b.', 'important data', 'aspects of traditional rehabilitation', 'ozan safak via unsplash', 'memory', 'faria', 'form of symbols', 'sessions', 'tool', 'increase in orientation', 'identification of targets', 'positive alternative', 'input', 'increase in language abilities', 'different tasks', 'cognitive rehab relies on paper-and-pencil tasks', 'further development of effective rehabilitation tools', 'motor skills', 'stroke', 'vr rehabilitation', 'minutes', 'chronic stage of stroke', 'frontiers in psychology', 'motivation', 'aguiar', 'larger-scale adoptions of vr', 'reinforcement of progress', 'chronic stroke', 'vr', 'numbers', 'further attention', 'pilot study', 'same period of time', 'future of rehabilitation', 'a. l.', 'strokes', 'vr program', 'costa', 'health professionals', 'continued work', 'executive functioning', 'vr program consisting', 'researchers']</b></p><p><br /></p><p>Furthermore, if I <i>only</i> look for keywords and not phrases, I use the following code: </p><pre><span style="font-weight:bold;">def </span><span style="color:#990000;font-weight:bold;">extract_candidate_words</span>(<span style="font-style:italic;">text</span>, <span style="font-style:italic;">good_tags</span><span style="font-weight:bold;">=</span><span style="color:#0086b3;">set</span>([<span style="color:#dd1144;background-color:#f7e7f1;">'JJ'</span>,<span style="color:#dd1144;background-color:#f7e7f1;">'JJR'</span>,<span style="color:#dd1144;background-color:#f7e7f1;">'JJS'</span>,<span style="color:#dd1144;background-color:#f7e7f1;">'NN'</span>,<span style="color:#dd1144;background-color:#f7e7f1;">'NNP'</span>,<span style="color:#dd1144;background-color:#f7e7f1;">'NNS'</span>,<span style="color:#dd1144;background-color:#f7e7f1;">'NNPS'</span>]))<span style="font-weight:bold;">:<br /></span><span style="font-weight:bold;"><br /></span><span style="font-weight:bold;">    </span>punctuation <span style="font-weight:bold;">= </span><span style="color:#0086b3;">set</span>(string.punctuation)<br />    stop_words <span style="font-weight:bold;">= </span><span style="color:#0086b3;">set</span>(nltk.corpus.stopwords.words(<span style="color:#dd1144;background-color:#f7e7f1;">'english'</span>))<br /><br />    tagged_words <span style="font-weight:bold;">= </span>itertools.chain.from_iterable(nltk.pos_tag_sents(nltk.word_tokenize(sent)<br />                                                                    <span style="font-weight:bold;">for </span>sent <span style="font-weight:bold;">in </span>nltk.sent_tokenize(<span style="font-style:italic;">text</span>)))<br /><br />    candidates <span style="font-weight:bold;">= </span>[word.lower() <span style="font-weight:bold;">for </span>word, tag <span style="font-weight:bold;">in </span>tagged_words<br />                  <span style="font-weight:bold;">if </span>tag <span style="font-weight:bold;">in </span><span style="font-style:italic;">good_tags </span><span style="font-weight:bold;">and </span>word.lower() <span style="font-weight:bold;">not in </span>stop_words<br />                  <span style="font-weight:bold;">and not </span><span style="color:#0086b3;">all</span>(char <span style="font-weight:bold;">in </span>punctuation <span style="font-weight:bold;">for </span>char <span style="font-weight:bold;">in </span>word)]<br /><br />    <span style="font-weight:bold;">return </span>candidates</pre><p><br /></p><p>And I get the following keyword candidates:</p><p><br /></p><p><b>['abilities', 'feedback', 'badia', 'executive', 'month', 'symbols', 'course', 'm.', 'alternative', 'increase', 'death', 'group', 'disability', 'improvement', 'program', 'input', 'cognitive-motor', 'someone', 'dominant', 'greater', 'therapy', 'g.', 'continued', 'areas', 'processes', 'cognitive', 'success', 'skills', 'couras', 'consisting', 'larger-scale', 'individuals', 'small', 'prevent', 'b.', 'feasibility', 'j.', 'curious', 'functioning', 'arm', 'o.', 'psychology', 'ways', 'identification', 'targets', 'participants', 'critical', 'health', 'progress', 'cause', 'method', 'seconds', 'attention', 'deliver', 'standard', 'difficulty', 'groups', 'safak', 'stage', 'training', 'cameir\xc3\xa3o', 'language', 'many', 'study', 'deficits', 'times', 'important', 'long-term', 'r.', 'tasks', 'letters', 'mobility', 'l.', 'image', 'period', 'outcomes', 'chronic', 'improvements', 'motor', 'tools', 'ozan', 'addition', 'positive', 'initial', 'development', 'memory', 'faria', 'function', 'aguiar', 'form', 'sessions', 'tool', 'immediate', 'newer', 'pilot', 'professionals', 'unsplash', 'double', 'work', 'vr', 'reinforcement', 'rehab', 'patients', 'future', 'strategies', 'minutes', 'rehabilitation', 'control', 'motivation', 'orientation', 'portugal', 'certain', 'states', 'stroke', 'numbers', '\xe2\x80\x99', 'aspects', 'f.', 'traditional', 'different', 'united', 'recovery', 'able', 'virtual', 'reality', 'high', 'improves', 's.', 'frontiers', 'week', 'competencies', 'strokes', 'adoptions', 'a.', 'levels', 'data', 'relies', 'costa', 'effective', 'paper-and-pencil', 'time', 'serious', 'researchers']<br /></b></p><p><br /></p><p>Neither of the above lists look too bad for the first draft of candidates.</p><p><br /></p><p>Next step is to use these candidates and extract the most meaningful ones as keywords and key phrases for our article. For this, I again use the NLTK library in tandem with a basic frequency statistic-based approach. Basically what I am doing is extracting keywords / phrases that are used most frequently and assuming they're the most important and meaningful for this article. There are many other ways to do this as well, which I will explore if our final recommendations don't turn out too great.</p><p><br /></p><p>But there is something more important to consider. While some keywords might seem important to our article, these keywords become quite useless in giving relevant recommendations in cases where such keywords occur in <i>all</i> or <i>most</i> NLT articles. To solve this problem, we use the <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a> (Term Frequency - Inverse Document Frequency) statistic. The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by 
the number of documents in the corpus that contain the word, which helps
 to adjust for the fact that some words appear more frequently in 
general.<br /></p><p><br /></p><p>To do this, I extracted the text from all articles on NLT and implemented the above described algorithms with the following code:</p><p><br /></p><pre><span style="font-weight:bold;">def </span><span style="color:#990000;font-weight:bold;">score_keyphrases_by_tfidf</span>(<span style="font-style:italic;">texts</span>, <span style="font-style:italic;">candidates</span><span style="font-weight:bold;">=</span><span style="color:#dd1144;background-color:#f7e7f1;">'chunks'</span>)<span style="font-weight:bold;">:<br /></span><span style="font-weight:bold;"><br /></span><span style="font-weight:bold;">    </span>boc_texts <span style="font-weight:bold;">= </span>[]<br />    <span style="font-weight:bold;">if </span><span style="font-style:italic;">candidates </span><span style="font-weight:bold;">== </span><span style="color:#dd1144;background-color:#f7e7f1;">'chunks'</span><span style="font-weight:bold;">:<br /></span><span style="font-weight:bold;">        </span>boc_texts <span style="font-weight:bold;">= </span>[extract_candidate_chunks(text) <span style="font-weight:bold;">for </span>text <span style="font-weight:bold;">in </span><span style="font-style:italic;">texts</span>]<br />    <span style="font-weight:bold;">elif </span><span style="font-style:italic;">candidates </span><span style="font-weight:bold;">== </span><span style="color:#dd1144;background-color:#f7e7f1;">'words'</span><span style="font-weight:bold;">:<br /></span><span style="font-weight:bold;">        </span>boc_texts <span style="font-weight:bold;">= </span>[extract_candidate_words(text) <span style="font-weight:bold;">for </span>text <span style="font-weight:bold;">in </span><span style="font-style:italic;">texts</span>]<br /><br />    dictionary <span style="font-weight:bold;">= </span>gensim.corpora.Dictionary(boc_texts)<br />    corpus <span style="font-weight:bold;">= </span>[dictionary.doc2bow(boc_text) <span style="font-weight:bold;">for </span>boc_text <span style="font-weight:bold;">in </span>boc_texts]<br /><br />    tfidf <span style="font-weight:bold;">= </span>gensim.models.TfidfModel(corpus)<br />    corpus_tfidf <span style="font-weight:bold;">= </span>tfidf[corpus]<br /><br />    <span style="font-weight:bold;">return </span>corpus_tfidf, dictionary</pre><pre>db <span style="font-weight:bold;">= </span>connector.connect(<br />    <span style="color:#660099;">host</span><span style="font-weight:bold;">=</span><span style="color:#dd1144;background-color:#f7e7f1;">'localhost'</span>,<br />    <span style="color:#660099;">user</span><span style="font-weight:bold;">=</span><span style="color:#dd1144;background-color:#f7e7f1;">'root'</span>,<br />    <span style="color:#660099;">passwd</span><span style="font-weight:bold;">=</span><span style="color:#dd1144;background-color:#f7e7f1;">''</span>,<br />    <span style="color:#660099;">database</span><span style="font-weight:bold;">=</span><span style="color:#dd1144;background-color:#f7e7f1;">'nlt_local'</span><span style="color:#dd1144;"><br /></span>)<br /><br />cursor <span style="font-weight:bold;">= </span>db.cursor()<br /><br />cursor.execute(<span style="color:#dd1144;background-color:#f7e7f1;">'SELECT </span><span style="color:#6666ff;background-color:#f7e7f1;font-weight:bold;">*</span><span style="color:#dd1144;background-color:#f7e7f1;"> FROM cms_article'</span>)<br /><br />texts <span style="font-weight:bold;">= </span>[]<br /><span style="font-weight:bold;">for </span>row <span style="font-weight:bold;">in </span>cursor<span style="font-weight:bold;">:<br /></span><span style="font-weight:bold;">    </span>soup <span style="font-weight:bold;">= </span>BeautifulSoup(row[<span style="color:#009999;">3</span>], <span style="color:#dd1144;background-color:#f7e7f1;">'html.parser'</span>)<br />    texts.append(soup.get_text())<br /><br />corpus, dictionary <span style="font-weight:bold;">= </span>score_keyphrases_by_tfidf(texts)</pre><p><br /></p><p>After extracting keywords and key phrases for all the NLT articles, following are the top 20 automatically extracted keywords / phrases we arrived at for the article we are demonstrating this on:</p><p><br /></p><pre>stroke                                                                      0.203810733679<br />pilot study                                                                 0.203810733679<br />vr program                                                                  0.193328996026<br />motor skills                                                                0.180123568313<br />strokes                                                                     0.175410347154<br />control group                                                               0.129819561207<br />participants                                                                0.115793943869<br />a. l.                                                                       0.110864691276<br />aguiar                                                                      0.110864691276<br />aspects of traditional rehabilitation                                       0.110864691276<br />cameirão                                                                   0.110864691276<br />cause of death                                                              0.110864691276<br />certain motor competencies                                                  0.110864691276<br />chronic stage of stroke                                                     0.110864691276<br />chronic stroke                                                              0.110864691276<br />cognitive improvements                                                      0.110864691276<br />cognitive rehab relies on paper-and-pencil tasks                            0.110864691276<br />cognitive-motor rehabilitation in virtual reality improves motor outcomes   0.110864691276<br />continued work                                                              0.110864691276<br />costa                                                                       0.110864691276<br /></pre><p><br /></p><p>Not terrible for a first draft. At least the top 5 seem to be strongly relevant. We can see that stemming the candidates might help as well (ex. stroke and strokes can be considered one keyword).<br /></p><p><br /></p><p>Let's see the keywords that the algorithm extracts if I consider only keywords and exclude key phrases.</p><p><br /></p><pre>rehabilitation                 0.381857768686<br />stroke                         0.344121312716<br />motor                          0.331168616651<br />vr                             0.28265753023<br />cognitive                      0.221686376772<br />tasks                          0.182246884551<br />rehab                          0.15170970009<br />paper-and-pencil               0.15170970009<br />chronic                        0.134521426331<br />strokes                        0.131812610176<br />greater                        0.0951246563211<br />pilot                          0.0942351697593<br />increase                       0.0893145674327<br />aguiar                         0.086998067593<br />cameirão                      0.086998067593<br />cognitive-motor                0.086998067593<br />couras                         0.086998067593<br />ozan                           0.086998067593<br />safak                          0.086998067593<br />abilities                      0.0858777529289</pre><p>Again, not at all bad for initial attempts. At least the top 10 keywords seem to be highly relevant. We do lose the power of a couple of relevant phrases like &quot;pilot study&quot; and &quot;motor skills&quot;.</p><p><br /></p><p class="authors">I am fairly happy with these results for now. I think I am simply going to extract the top 10 key phrases and top 10 keywords and attach them to each of the NLT articles. Once I attach them, I can move forward with identifying articles of highest relevance to a given article using these keywords and key phrases and see how that turns out. I'll demonstrate my work on that in the second part of this blog post.<br /><br />But before I sign off, let's have some fun and see how this algorithm works with other posts published on NLT by other members of our staff.<br /><br />1. <a href="https://newlearningtimes.com/cms/article/5566/the-public-art-project-that-will-never-be-finished" target="_blank">The Public Art Project That Will Never Be Finished</a></p><p class="authors">By Rebecca Sullivan</p><p class="authors">Manually added keywords: None<br /></p><pre class="authors">lightwalk<br />abilene christian university<br />acu<br />aesthetic project<br />artistic displays<br />interaction enhances experience<br />interactive light display<br />light walk<br />new effect codes<br />public displays like acu ’</pre><pre>lightwalk<br />acu<br />displays<br />display<br />artistic<br />abilene<br />quad<br />public-facing<br />light<br />enhances<br /></pre><p class="authors"><br /></p><p class="article-name">2. <a href="https://newlearningtimes.com/cms/article/5557/brian-hill" target="_blank">Brian Hill</a></p><p class="article-name">By George Nantwi</p><p class="article-name">Manually added keywords: <b>incarceration, recidivism, communication tools</b><br /></p><pre class="authors">edovo<br />incarcerated population<br />sib<br />recidivism<br />supporter<br />corrections<br />impact<br />father<br />majority<br />hope</pre><pre>edovo<br />incarcerated<br />correctional<br />corrections<br />reentry<br />jd/mba<br />jail<br />prison<br />hill<br />re-entry<br /></pre><p class="authors"><br /></p><p class="authors">3.<a href="https://newlearningtimes.com/cms/article/5545/claudia-recchi" target="_blank">Claudia Recchi</a></p><p class="authors">By Ryan Allen</p><p class="authors">Manually added keywords: <b>higher education, evaluations, modernize</b><br /></p><pre class="authors">edsights<br />professors<br />classpulse<br />sister<br />students<br />instructors<br />anonymous tumblr forum<br />big name universities<br />ceo of edsights<br />claudia recchi</pre><pre>edsights<br />professors<br />classpulse<br />recchi<br />claudia<br />sister<br />seminars<br />insightful<br />anonymous<br />feedback<br /></pre><p class="authors"><br /></p><p class="article-name">4. <a href="https://newlearningtimes.com/cms/article/5563/how-green-energy-could-change-the-saharas-climate" target="_blank">How Green Energy Could Change the Sahara’s Climate, and One Rocket Scientist’s Inspiring Story</a></p><p class="article-name">By Will Carington</p><p class="article-name">Manually added keywords:<b> Climate, Homelessness, China, Space</b><br /></p><pre class="authors">full story from motherboard<br />girl scout<br />homeless get ids<br />jordan bebek via unsplash<br />large-scale solar<br />scientist.full story from npr<br />state.full story from thrillist image<br />u.s. in ai development<br />wind farms<br />sahara</pre><pre>motherboard<br />bebek<br />state.full<br />thrillist<br />sahara<br />scientist.full<br />ids<br />farms<br />jordan<br />wind<br /></pre><p class="authors"><br /></p><p class="authors">5. <a href="https://newlearningtimes.com/cms/article/5580/learning-theater-spotlight-combining-technology" target="_blank">Learning Theater Spotlight: Combining Technology and Performance in the Learning Theater</a></p><p class="authors">By EdLab Studios and Sara Hardman</p><p class="authors">Manually added keywords: None<br /></p><pre class="authors">participants<br />absum by nctrnm<br />actual performances<br />annual summer program<br />design workshops<br />final piece<br />first week of literacy unbound<br />high school english teachers<br />literacy unbound participants<br />multimedia producer at edlab</pre><pre>ruta<br />unbound<br />theater<br />participants<br />literacy<br />absum<br />kruliauskaite<br />nctrnm<br />upton<br />workshop</pre><p><br /></p><p>Results seem to be alright. Comments and suggestions will be much appreciated. :-)<br /></p><p>
        
        </p><div class="col-xs-2">
            <div class="article-interact-icons pull-right">
                <div class="btn-group btn-group-sm" role="group">
                </div></div></div>
          </p>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">
          Copyright &copy; EdLab 2019 <script>new Date().getFullYear()>2019&&document.write("-"+new Date().getFullYear());</script>
        </p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script
      src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
      integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
      integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
      integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
